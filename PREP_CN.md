# 项目深度解析 (Factorio Agent)

这份文档是我对自己构建的Factorio游戏AI Agent项目的全面复盘。我将以第一人称视角，详细阐述从项目构思、架构设计到技术实现的每一个环节、选型考量和具体步骤。

## 一、 核心理念与顶层架构

### 1.1 项目目标
我的核心目标是创建一个“思考型”AI玩家，而非“脚本型”机器人。它需要具备以下能力：
- **理解意图**: 能理解玩家用自然语言下达的模糊指令。
- **自主规划**: 能将复杂任务分解为一系列可执行的步骤。
- **知识驱动**: 能查询和利用外部知识（游戏攻略、API文档）来辅助决策。
- **动态执行与适应**: 能与游戏环境交互，并根据结果调整后续行为。

### 1.2 架构选择：ReAct框架下的多智能体协作
我设计的架构是一个基于**ReAct (Reasoning and Acting)** 思想的**多智能体（Multi-Agent）**系统。

**指令生命周期如下:**

`用户输入` -> `[GameAgent]` -(规划)-> `[KnowledgeBase (RAG)]` -(知识)-> `[GameAgent]` -(委托)-> `[CodingAgent]` -(代码)-> `[ToolManager]` -(执行)-> `Factorio RCON` -> `游戏状态反馈` -> `[GameAgent]` -> ... (循环)

- **GameAgent (`game_agent.py`):** **大脑/指挥官**。负责高层逻辑、任务规划、理解用户意日志和维护长期目标。它决定*做什么*。
- **KnowledgeBase (`knowledge_base/`):** **记忆/知识库**。基于RAG，为所有Agent提供决策所需的知识。
- **CodingAgent (`coding_agent.py`):** **手/工程师**。负责将`GameAgent`的指令转换成精确、可执行的游戏脚本代码。它决定*怎么做*。
- **ToolManager (`unified_tool_manager.py`):** **执行器**。负责调用Agent生成的动态工具或固定的静态工具。

之所以选择多Agent，是因为**专业化**能极大降低系统复杂度。`GameAgent`的Prompt可以专注于策略和规划，而`CodingAgent`的Prompt可以专注于代码的准确性和格式，二者互不干扰，易于维护和优化。

## 二、 RAG知识库的构建 (从0到1的步骤)

这是项目的基石。我将它分为数据源、分块、嵌入和存储四个阶段。

### 阶段一：数据采集 (Crawling)
我需要两种核心知识：游戏玩法（非结构化）和API信息（结构化）。

1.  **Wiki数据 (`factorio_wiki_crawler.py`):**
    - **工具**: 使用 `requests` 库获取HTML，`BeautifulSoup4` 库进行解析。
    - **策略**: 我编写了爬虫，定向抓取Factorio官方Wiki上的核心页面，如“Items”, “Recipes”, “Tutorials”等。我重点提取了页面的主要内容区域（如`div#mw-content-text`），过滤掉导航栏、侧边栏等噪声。
    - **产出**: `data/raw/wiki_pages.json`，一个包含页面URL和其纯文本内容的JSON文件。

2.  **API数据:**
    - **来源**: Factorio游戏本身可以导出完整的运行时API定义，我将其保存为`data/raw/runtime-api.json`。
    - **特点**: 这是高度结构化的JSON，包含了游戏所有的类、方法、事件和数据结构。

### 阶段二：文本分块 (Chunking)
分块的质量直接决定了检索效果。我对不同数据源使用了不同策略。

1.  **Wiki文本 (`langchain_spliter.py`):**
    - **工具**: LangChain的 `RecursiveCharacterTextSplitter`。
    - **参数**: `chunk_size=1000`, `chunk_overlap=200`。
    - **选型理由**: 这是一个反复试验后的选择。1000个字符的块大小足以包含一个完整的概念或一个操作步骤（例如一个完整的合成配方），而200个字符的重叠区确保了在块切割处不会丢失重要的上下文联系。`RecursiveCharacterTextSplitter`会优先尝试按段落、句子等语义边界切分，这比简单的固定长度切分效果好得多。

2.  **API JSON (自定义脚本):**
    - **策略**: 我没有直接对JSON用文本分割器，因为这会破坏其结构。我编写了一个自定义的Python脚本 (`processor/`下的某个脚本)来解析`runtime-api.json`。
    - **方法**: 我遍历JSON树，**以每个“类(class)”或顶层“函数(function)”的定义为一个独立的文档（Document）**。每个文档包含了该类/函数的完整描述、所有方法、参数和返回类型。
    - **理由**: 这种**语义分块**确保了`CodingAgent`在检索时，获取到的是一个完整、立即可用的API上下文，而不是一个被拦腰截断的代码片段。

### 阶段三：向量化 (Embedding)
这是将文本转换为机器可理解的向量的过程，核心目的是让下游检索和语义匹配具备高效、准确的基础。

#### 1. **模型选择**: `sentence-transformers/all-MiniLM-L6-v2`
   - **选型理由**:
     - **性能优异**：该模型在MTEB（Massive Text Embedding Benchmark）排行榜上表现突出，尤其是在语义检索和技术文档等领域任务中，兼顾速度与准确率。
     - **本地部署灵活**：通过`HuggingFace Transformers`和`SentenceTransformers`库，可以在本地直接运行，无需依赖云端API。这不仅节省了调用OpenAI Embedding API的费用，还消除了网络延迟，极大提升了Agent的实时响应能力。
     - **自主可控**：本地化部署意味着嵌入过程完全由自己掌控，不受第三方API速率、配额等限制，便于大批量数据处理和定制化优化。
     - **资源友好**：MiniLM架构轻量，适合在普通GPU甚至部分CPU环境下快速批量推理，适合生产环境和原型开发。

#### 2. **实现细节 (`embedding_processor.py`):**
   - 首先加载`sentence-transformers/all-MiniLM-L6-v2`模型实例。
   - 对所有已分块（chunked）的文本逐块遍历，调用`model.encode()`方法将每个文本块转化为归一化后的高维向量（embedding）。
   - 归一化处理（如L2标准化）有助于后续相似度计算（如余弦距离），提升检索准确性和稳定性。
   - 嵌入向量会与原始文本及元信息一起存入向量数据库，确保后续检索和溯源流程的完整性。

#### 3. **补充说明**
   - 该阶段为整个RAG系统的核心环节之一，嵌入质量直接影响检索效果和Agent最终生成答案的可靠性。
   - 在实际项目中，可根据业务场景尝试不同embedding模型（如BGE、E5、领域微调模型），并对分块策略和归一化方式进行调优。

### 阶段四：存储与索引 (Vector Store)

我需要一个高效的方案来存储向量并执行相似度搜索。

#### 1. 工具选择：FAISS (Facebook AI Similarity Search)
 - 选择理由:
    - 速度与可控性：FAISS 为稠密向量相似度搜索而生，提供多种索引结构，能在“精度-速度-内存”之间细粒度取舍。
    - 本地化：C++ 核心、Python 封装；与我本地离线处理和本地 Agent 的架构契合，避免服务化开销。
    - 渐进式优化空间：先用精确索引（Flat）确保质量，随着数据量增长再切换到 IVF/HNSW/PQ 或 GPU 加速。
 - 为什么是 IndexFlatL2
    - 数据规模：我的向量规模在几万到几十万。这个量级使用暴力 L2 搜索依然能达到毫秒级延迟（结合批量/并行），且无需训练索引。
    - 结果质量：Flat 是精确搜索，Recall=100%。在需要检索高精度 API/知识片段的场景下，优先确保答案正确性。
    - 实现简洁：无需额外训练与超参调优，迭代快，便于把时间花在数据清洗与评测上。

> 提示：若对向量做了 L2 归一化，则 L2 距离与余弦距离在排序上等价。此时也可以用 IndexFlatIP（点积）实现“余弦相似度”的效果。两者择一保持一致性即可。

#### 2. 维度说明
 - 本文上游嵌入模型为 sentence-transformers/all-MiniLM-L6-v2，输出维度为 384。因此索引维度 d=384。
 - 若后续切换到 BGE/E5 等模型，请同步更新索引维度（例如 bge-base 常见为 768；部分大模型嵌入可达 1024）。

#### 3. 实现（vector_store_processor.py）
 - 流程概述
    1. 创建 `faiss.IndexFlatL2(d)` 索引，d 为嵌入维度（此处为 384）。
    2. 将全部嵌入向量（NumPy float32 矩阵，形如 [N, d]）批量 `index.add(vectors)`。
    3. 使用`faiss.write_index()`将构建好的索引序列化到磁盘，即`data/processed/kb/all_faiss_index.bin`。
    4. 同时，我将原始的文本块与它们的向量索引位置一一对应，存储在一个pickle文件里（如`all_chunks_data.pkl`），以便在检索到向量ID后能快速找回原文。
 
#### 4. 可选优化（数据增大后的演进）
 - IVF（倒排文件）系列
    - `IndexIVFFlat`、`IVF,PQ`：需对训练样本做 k-means 训练，查询时只搜索部分簇以降低延迟。
    - 关键参数：nlist（簇数）、nprobe（查询时扫的簇数）。nprobe 越大召回越高但越慢。
    - 适用：百万级数据起，或对延迟更敏感的场景。
 - HNSW（图索引）
    - 小内存下也可取得较好性能与 Recall，构图参数 m/efConstruction，查询参数 efSearch 控制速度/召回。
    - 适用：需要无需训练、增量插入友好、较高 Recall 的近似搜索。
 - PQ/OPQ（产品量化）
    - 大幅节省内存与 IO，适合超大规模库；精度会有一定损失，可配合重排（Rerank）提升最终质量。
 - GPU 加速
    - 安装 faiss-gpu 后，Flat/IVF 等在 GPU 上可显著降低延迟；适合高并发/低延迟检索服务。

#### 5. 对比 Chroma 的取舍说明（总结版）
 - 选 FAISS，我获得：
    - 极致可控的检索性能与索引选择空间；
    - 轻量本地依赖、易与现有 Python 管线耦合；
    - 平滑升级路径（Flat → IVF/HNSW/PQ → GPU）。
 - 放弃 Chroma，我承担：
    - 自行维护元数据、过滤查询和序列化流程；
    - 若需多集合/复杂筛选，需要自己设计一层数据访问封装。

对我当前以“嵌入质量与精确检索”为核心的小型知识库场景，FAISS 更贴合“高质检索 + 本地可控 + 迭代快速”的目标，因此最终选择了 FAISS。

## 三、 Agent与Prompt工程

### 3.1 GameAgent: 策略大脑
`GameAgent`的核心是它的系统提示（System Prompt），我设计的Prompt包含以下要素：
- **角色定义**: "你是一个《异星工厂》的专家级玩家和指挥官..."
- **核心任务**: "你的任务是理解用户的指令，将其分解为逻辑步骤，并协调其他工具和Agent来完成它。"
- **工具列表**: 明确列出它能使用的工具，例如 `knowledge_search(query: str)` 和 `delegate_to_coder(task_description: str)`。
- **输出格式 (ReAct)**: 强制要求它遵循`Thought -> Action -> Observation`的循环。
    - **Thought**: 解释它当前的思考过程。
    - **Action**: 以JSON格式指定要调用的工具和参数。
    - **Observation**: （由系统填充）工具执行的结果。

### 3.2 CodingAgent: 代码专家
`CodingAgent`的Prompt更具技术性：
- **角色定义**: "你是一个精通Factorio Lua和Python脚本的编程专家..."
- **任务**: "你将收到一个具体的任务描述和相关的API文档片段。你的唯一目标是编写一段完整、无误、可直接执行的脚本来实现这个任务。"
- **严格规则**:
    - "不要写任何解释性文字，只输出代码。"
    - "使用从上下文中提供的API，不要杜撰函数。"
    - "确保代码是自包含的。"
- **上下文提供**: 在每次调用`CodingAgent`时，我不仅提供任务描述，还会把从RAG中检索到的最相关的API文档块一并塞入Prompt中。

### 3.3 动态工具生成
`src/agent/tool/generated/`目录是这个架构的点睛之笔。
当`CodingAgent`生成一段脚本（例如`place_burner_mining_drill.py`）后，`UnifiedToolManager`会：
1. 将代码写入该目录下的一个临时文件。
2. 使用Python的`importlib`或`subprocess`动态加载并执行这个脚本。
3. 捕获执行的输出或异常。
4. 将结果作为`Observation`返回给`GameAgent`。
这实现了真正的**运行时工具创建**，赋予了Agent极大的灵活性。

## 四、 评估、局限与未来方向

### 4.1 如何评估
- **RAG评估**: 我建立了一个包含约50个问题的“黄金标准”问答对（例如，问题：“铁齿轮怎么造？”，期望答案：包含铁板和时间的配方）。通过运行这些问题，我计算**Top-3检索结果的命中率**来评估RAG流水线的健康度。
- **任务完成度**: 我设计了10个从易到难的端到端任务（例如，“自动化生产铜线”），通过Agent执行并记录成功率和完成步骤数，以此来衡量整个系统的表现。

### 4.2 RAG进阶优化：应对检索不匹配问题 (规划与思考)

在项目实践中，我意识到基础的RAG系统存在一个核心挑战：用户的提问方式千变万化，有时会导致检索到的上下文质量不高或不相关，进而影响Agent的决策。虽然目前系统可用，但要达到更高水平的鲁棒性，我规划了以下几个进阶优化策略：

#### 策略一：查询重写与扩展 (Query Rewriting & Expansion)

- **问题**: 用户查询通常很短或口语化（如“搞点矿”），而知识库中的文本是书面和技术性的（如“放置热能采矿机在铁矿上”）。这种不匹配导致检索效果不佳。
- **解决方案**: 在进行向量搜索**之前**，先用LLM对原始查询进行“加工”。
- **实现思路**:
    1.  创建一个特定的Prompt，要求LLM扮演一个“搜索专家”。
    2.  **查询重写(Rewriting)**: 将用户的模糊查询改写得更具体。例如，Prompt可以是：`“请将以下《异星工厂》玩家的模糊指令，改写成一个清晰、详细、适合给向量数据库检索的查询。原始指令：{user_query}”`。 “搞点矿” -> “如何在游戏初期手动放置采矿机来采集铁矿或铜矿”。
    3.  **查询扩展(Expansion)**: 生成多个相关的子查询，从不同角度进行搜索，然后合并结果。例如，对于“怎么做红瓶”，可以扩展为 `[“红色科技包的合成配方”, “自动化生产红色科技包的工厂布局”, “研究自动化科技需要什么前置条件”]`。进行多次搜索后，对结果进行合并和去重，能更全面地覆盖用户意图。

#### 策略二：两阶段检索——重排模型 (Re-ranking)

- **问题**: 向量检索（召回阶段）为了速度，牺牲了一部分精度。它返回的Top-K结果里，最相关的可能排在第5，而不是第1。
- **解决方案**: 引入一个更“精细”的模型，对初步召回的结果进行重新排序。
- **实现思路**:
    1.  **召回 (Recall)**: 使用FAISS快速从海量文档中召回Top 20-50个候选块。这个阶段的目标是“宁可错杀，不可放过”，确保相关文档大概率在这个集合里。
    2.  **重排 (Re-rank)**: 使用一个**交叉编码器 (Cross-Encoder)** 模型。与生成单一向量的双编码器（如BGE）不同，交叉编码器会同时接收`[查询, 文档块]`对作为输入，并直接输出一个0到1之间的相关性分数。它的计算量大，但精度极高。
    3.  **具体流程**: 我会遍历召回的50个候选块，分别与原始查询组成对，喂给交叉编码器。然后根据得到的相关性分数从高到低排序，选取分数最高的Top 3-5个块作为最终的上下文，传递给Agent。

#### 策略三：混合搜索 (Hybrid Search)

- **问题**: 纯向量搜索擅长理解语义，但可能忽略掉特定的关键词，尤其是那些在模型训练语料中不常见的专有名词（如某个具体物品的ID `burner-mining-drill`）。
- **解决方案**: 结合**关键词搜索**（如BM25算法）和**向量搜索**的优点。
- **实现思路**:
    1.  **双路检索**: 对用户的每一个查询，同时在两个系统里进行搜索：
        - **向量搜索**: 在FAISS中进行，找出语义上最相似的Top K个结果。
        - **关键词搜索**: 我会为所有文档块额外建立一个BM25索引（可以使用`rank_bm25`库）。它会找出关键词匹配度最高的Top K个结果。
    2.  **结果融合 (Result Fusion)**: 使用**倒数排序融合 (Reciprocal Rank Fusion, RRF)** 算法将两个排序列表合并成一个。RRF算法简单有效，它不关心原始分数的大小，只关心排名，能很好地结合两种不同搜索系统的结果。

通过实施以上一个或多个策略，我可以显著提升RAG系统的检索质量，从而让Agent获得更准确、相关的知识，做出更可靠的决策。这部分是我下一步迭代的核心方向。

### 4.3 未来工作
1.  **引入视觉能力**: 集成多模态模型（如GPT-4V），让Agent能“看到”游戏画面，从而理解基地布局、识别传送带瓶颈等，实现真正的视觉感知。
2.  **长期记忆**: 当前记忆主要依赖RAG和会话历史。我会构建一个独立的记忆模块（可能用SQLite或更复杂的时序向量数据库），让Agent能记住长期的战略目标和关键的游戏事件。
3.  **更复杂的Agent间协作**: 从简单的“委托”模式升级到更复杂的“讨论”或“投票”模式。例如，在规划复杂基地布局时，可以有一个`PlannerAgent`和一个`ValidatorAgent`进行多轮对话来优化方案。

---
这份文档总结了我项目的核心技术细节和设计哲学。我相信它展示了我在Agent架构、RAG应用和工程实践上的深入思考和动手能力。